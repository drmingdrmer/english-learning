# Raft（不是）万能：如何使其更加健壮

[原文链接](https://dev.to/tarantool/raft-notalmighty-how-to-make-it-more-robust-3a11)

[![Image description](raft-notalmighty-how-to-make-it-more-robust.en.assets/mt0wckqsxaqv041ulfw3-20240131104950569.png)](https://res.cloudinary.com/practicaldev/image/fetch/s--sRlhwn_T--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/mt0wckqsxaqv041ulfw3.png)

大家都喜欢 Raft。普遍认为，在分布式系统中使用 Raft 算法意味着该系统将一切都很好。具体来说：

1. 只要集群中的大多数节点处于活动状态并相互连接，集群将是可写的（在选举领导者时会有暂停）。
2. 如果领导者正常工作并与大多数节点连接，集群将始终是可写的。
3. 如果领导者宕机，将“快速”选择新的领导者——不管这意味着什么。

事实上，仅仅遵循 Raft 规范（[raft.pdf](https://raft.github.io/raft.pdf) 或 Diego Ongaro 的博士论文版本）是不足以实现上述所有内容的。即使 etcd 也曾因此遭受过打击，导致了 [2020 年的 Cloudflare 中断](https://blog.cloudflare.com/a-byzantine-failure-in-the-real-world/)。

我叫 Sergey Petrenko，我在 Tarantool 上进行复制工作已经有 4 年了。今天我想告诉大家 Raft 算法的弱点以及如何克服它们。本文是我和 Boris Stepanenko 在 [Hydra 2022](https://hydraconf.com/talks/f7082c470b8f4ddd894a940f892f40fb/) 上的演讲的自由转述。如果你对 Raft 不熟悉，我建议你先阅读[我的这篇文章](https://dzone.com/articles/raft-in-tarantool-how-it-works-and-how-to-use-it)。

让我从稍远的地方开始。假设你有一个使用 Raft 的系统，并希望将其用于生产环境。我们都听说过，不止一次地听说过，Raft 保证每个任期内只有一个领导者，并且它可以在集群中失去不到一半节点的情况下保持性能。也就是说，如果领导者活着，它将能够处理条目，如果没有领导者，将选择一个新的领导者。除了这些保证，似乎我们对系统的长时间运行并不需要其他任何东西。事实真的是这样吗？我们即将找出答案。

首先，让我们更仔细地看看集群只要大多数服务器处于活动状态并相互连接就能保持运行的说法。对这个说法的误解最终导致了 Cloudflare 的中断。

## 预投票

我们从一个例子开始，看看在部分连接丢失的情况下 Raft 集群的行为。

假设我们的集群由三个节点 A、B 和 C 组成。A 是领导者，B 和 C 是它的副本；现在是第 2022 个任期。那么 A 和 C 之间的连接丢失会导致什么结果呢？在选举超时时间内，如果领导者没有发送心跳信号，服务器 C 就会认为领导者丢失，并在第 2023 个任期中开始选举。

服务器 B 是唯一一个服务器 C 可以向其发送 RequestVote 请求的服务器。

一旦服务器 B 收到一个更大任期的请求，它也会增加自己的任期。然而，它不一定会投票给 C，因为如果领导者在 A 和 C 之间的连接丢失后写入了一些数据，B 可能拥有更新的数据。

在接收到下一条来自领导者（仍然是服务器 A）的消息后，服务器 B 将报告任期已经增加，迫使服务器 A 辞职。集群没有领导者，所以选举开始。在选出领导者之前，集群是不可写的。

如果自连接丢失后没有新的条目，那么一旦服务器 B 收到服务器 C 的 RequestVote，它将投票给服务器 C。

如果发生这种情况，我们就陷入了一个无限循环中：

1. 服务器 C 看不到领导者。
2. 当选举超时到期时，服务器 C 开始新的选举。
3. 通过服务器 B，任期的增加传达给了服务器 A。
4. 服务器 B 投票给服务器 C，所以
5. 服务器 A 辞职。
6. A 和 C 交换位置，然后从步骤 1 开始重复，但在新的任期中。

连接到这样一个有闪烁领导者的集群的客户端很可能根本无法写入任何内容。一旦选出了行动中的领导者，并且客户端尝试执行写操作，领导者就会辞职，甚至不知道应该将写请求转发到哪里，因为它无法直接看到新的领导者。这种情况会一直持续下去，直到奇迹般地至少有一个条目可以被写入，或者直到 A 和 C 之间的连接恢复。这正是 Cloudflare 在 etcd 上发生的情况。外部系统非常合理地认为，如果它无法向 etcd 集群写入任何内容，那么它意味着其中大多数节点已经失败，应该采取紧急措施。etcd 不可写的短短 6 分钟导致了超过 6 小时的事故。

你可能会觉得 Raft 的一些保证在这里被违反了。实际上，并没有。

每时每刻，领导者都与大多数节点（包括自己）相连，并且领导者本身不会失败。然而，我们的期望被打破了。集群无法正常运行。

但问题是，Raft 从未承诺在这种情况下能够正常运行。它的承诺是“如果大多数节点都是正常的并相互连接，将会选择一个领导者”。它根本没有提到领导者是永久的。而且选择领导者的保证实际上并没有被违反。在上面的例子中，它大约每个选举超时时间确定一次。实际上，Raft 的保证在实践中是不足够的。

但这还只是一半的麻烦。

让我们回到第 2022 个任期，并假设在节点 A、B 和 C 的集群中，节点 C 与其他节点失去了所有通信。服务器 A 是领导者，仍然与服务器 B 连接，并且可以处理写请求。到目前为止，一切都好。

服务器 C，就像上面的例子一样，每个选举超时时间都会开始一次新的选举。当然，服务器 C 不可能赢得任何选举。它只是无法获得多数选票。然而，它的任期将无限增长，并且在恢复连接的那一刻，服务器 A 再次看到更大的任期时就会辞职。集群再次变为只读状态，至少进行一轮选举，但没有明显的原因。

## Raft 的解决方案

这种“干扰性”服务器的问题实际上是 Raft 的作者 Diego Ongaro 在他的博士论文中提到的。然而，他将它们与配置更改联系在一起。

他提出的解决方案是称为 Pre-Vote 的选举的新阶段。其思想是每个服务器在选举之前向所有人发送一个模拟投票请求，称为 PreVote。该请求包含与普通的 RequestVote 相同的字段，投票者根据与 RequestVote 相同的规则对其进行响应。唯一的区别是，投票者在收到此请求时不会增加任期，并且如果它仍然在当前任期中看到领导者，则会否定或简单地忽略该请求。

只有在收到大多数选民准备为其投票的确认后，候选人才会提升任期并开始真正的选举。

让我们检查一下 PreVote 是否真的可以拯救 Cloudflare 那次事故。考虑相同的情况，C 与领导者失去了连接，但与其他副本没有失去连接。尽管 C 可以向 B 发送 PreVote 请求，但 B 将否定该请求，因为它仍然看到领导者。C 将无法获得多数选票 —— 它的 PreVote 请求只会得到 2 个否定的回答。

在完全失去连接并随后恢复连接的情况下，PreVote 也会有所帮助。确实，服务器 C 将无法获得任何 PreVote 请求的响应，因此不会开始选举。

这种解决方案对我们来说唯一的缺点是违反了向后兼容性。Raft 在 Tarantool 中已经运行了一段时间，协议中没有 PreVote 请求。当然可以添加，但旧的服务器不知道如何处理新的请求。我们必须在发送方引入新的逻辑：如果服务器是旧的，我们不会向其发送 PreVote 请求，并默认假设它肯定回应。我们不喜欢这种冗余，而且希望摆脱为支持旧版本而存在的额外代码。更好的解决方案是扩展现有请求之一。旧的服务器只会忽略现有请求中的新字段，因此不需要额外的逻辑。所以这就是我们选择的方式。

## 我们的解决方案

“在 Tarantool 中，服务器足够聪明，不会在不必要的情况下开始选举”，我们这样想，并且我们按照我们自己的方式进行了 Pre-Vote。我们让所有副本告诉其他副本它们是否看到当前的领导者。收集到关于谁看到领导者和谁没有看到领导者的信息后，你可以决定是否开始选举。如果有任何人看到领导者，或者如果与大多数节点没有连接，就不会启动选举。

我们解决方案的优势在于它的向后兼容性。我们不需要引入新的请求，并以特殊的方式将其发送到旧的服务器，即使集群中有不同版本的 Tarantool 服务器也没有问题。

缺点是我们不会比较领导者的日志和选民的日志，这意味着我们会在选举开始时忽略选民日志中的更新数据。这不一定是件坏事：只要有人看到领导者，就不会发生选举。当每个人都不再看到领导者时，选举将无论如何开始。选举是否在一个或多个轮次中结束并不重要，这要归功于我们的另一个修改，Split-Vote 检测。现在，让我们来谈谈它。

## Split-Vote 检测

这次我没有一个像 Cloudflare 或其他著名公司的可怕案例，但希望它仍然很有趣。

你可能知道，并不是每一轮选举都会产生一个领导者。例如，如果集群中的几个节点同时注意到领导者丢失，它们将在彼此收到 RequestVote 请求之前独立开始选举。剩下的副本的选票可能会分散在几个候选人之间，以至于没有一个候选人能够赢得多数选票。我们将这种情况称为 Split-Vote。

Raft 通过随机化选举超时时间来处理这个问题。在每个服务器和每一轮中，都会选择一个与配置值略有不同的新随机值。这增加了只有一个候选人有时间开始下一轮选举的机会，而其他候选人在自己的选举超时时间到期之前会收到它的 RequestVote 请求。如果 Raft 没有实现这一点，选举可能永远不会结束：所有服务器都会同步重新启动，为自己投票。但仍然有优化的空间：每一轮额外的选举都是只读集群停机的选举超时时间。

## 我们的解决方案

实际上，以平局结束的轮次是浪费时间的。如果已经选出了一个领导者，它可能在轮次开始时就已经产生了（大约在最远的服务器的数据包交换时间内）。根据 Raft 的规定，选举超时时间要比这长得多。

此外，与经典的 Raft 实现不同，在 Tarantool 中，服务器不仅向其投票的候选人发送投票信息，还向所有集群成员发送投票信息。这意味着每个服务器都可以跟踪每个候选人收到的选票数。当看到没有候选人能够在当前轮次中获胜时，服务器会加快开始新轮次的速度。从检测到平局到开始新轮次平均需要 0.05 * 选举超时时间。这是因为我们在选举超时时间 / 10 的范围内选择一个随机延迟来重新启动选举。我们之所以这样做，完全是出于与 Raft 相同的目的：避免新的平局。因此，在最好的情况下，我们在每个平局轮次上节省了大约 0.9 * 选举超时时间。这种改进是非常明显的：在原始的 Raft 中，在两轮选举中选出领导者意味着需要花费大约选举超时时间 + 选举超时时间的一部分时间。然而，在我们的实现中，两轮这样的选举只需要花费选举超时时间的一小部分时间。这比原始的 Raft 意识到发生平局所需的时间更快。

在最坏的情况下，当连续发生两次平局时，我们处理得更快。对我们来说，每一轮平局实际上是没有成本的。此外，我们不会以任何方式增加第二次平局的概率：在这种情况下，重新启动选举的随机延迟在与常规情况下相同的范围内生成。

## CheckQuorum

Raft 确保在一个任期内不会有两个领导者。然而，并没有说在同一时间可能存在两个领导者的可能性：在旧任期和新任期中。我们当然希望避免这种情况的发生。原因是连接到旧领导者的客户端可能不知道有新领导者存在。直到旧领导者实际辞职之前，他们根本没有理由寻找新领导者。旧领导者仍然是可写的，同步事务将在未能从大多数副本获得确认后被回滚。

对于我们来说，同一时间存在两个领导者的情况可能是关键的，因为 Tarantool 不仅支持同步复制，还支持异步复制。每个领导者都是可写的，如果你在旧领导者上写入异步事务，客户端可能会忽略新领导者的存在。这将导致一些客户端联系新领导者，而另一些客户端联系旧领导者。我们将会遇到分裂大脑的情况。为了避免这种情况，旧领导者必须在有可能被取代的情况下辞职并进入只读状态。

只有当旧领导者与集群中大多数服务器失去连接时，才有可能存在两个领导者的情况。确实，要赢得选举，必须获得多数选票，旧领导者之所以不知道选举的情况，是因为它与大多数节点没有连接。如果它与至少一个投票给新领导者的服务器连接，它将立即辞职。旧领导者不可能与没有投票的大多数节点连接，并且同时新领导者与投票多数节点连接的情况是不可能的。

因此，我们希望确保领导者在失去与集群大多数节点的连接时立即辞职。如果当前领导者的连接丢失，很可能大多数已经选择了另一个领导者。

CheckQuorum 的另一个原因是没有它，仅仅通过 PreVote 就可以导致集群被锁定：当前领导者无法写入任何内容，副本也无法开始选举。让我们看一个例子：假设我们有一个由五个服务器组成的集群，其中 D 是领导者。接下来发生了一系列非同寻常的事件：首先，服务器 E 崩溃，然后由于某种原因 A 和 D 之间的连接中断，最后，由于另一种原因，C 和 D 之间的连接中断。

结果，尽管服务器 D 仍然是领导者，但它无法提交同步事务，因为它无法获得三个确认。服务器 B 不会开始选举，因为它仍然看到领导者 D。服务器 A 和 C 不会开始选举，因为服务器 B 告诉它们领导者仍然活着。

CheckQuorum 通过使失去与大多数集群连接的领导者辞职并允许副本之一接替其位置来帮助解决这个问题。

还需要决定领导者应该在什么时候辞职。对于被阻塞的集群示例，实际上并不重要。这里的主要问题是领导者最终会辞职，使其副本能够开始选举。

如果只涉及同步复制，一切都会很好。辞职的速度也不重要。旧领导者无法确认连接中断后的任何同步事务。

如果涉及异步事务，你必须采取一些措施来确保一致性。

**最低要求**是旧领导者必须在副本能够选出新领导者之前**严格**辞职。这是为了确保集群不会同时存在两个可写节点。我们将这种模式称为严格的 CheckQuorum。

但这还不够。我们无法保证在连接失败后不会写入任何异步事务。无论如何，要检测到连接失败，都需要一些时间，无论多短。这意味着旧领导者可能会写入新领导者没有的事务。当连接最终恢复时，事务将到达其他节点，并且新领导者写入的所有内容的一致性可能会受到损害。因此，我们的最终目标。

**最终目标：**在恢复连接后，新领导者及其所有副本不得应用由前任领导者记录的事务。我们将在下一章中更详细地介绍这个问题，但现在让我们讨论如何实现所需的最低要求。

领导者和副本都通过心跳监视连接的状态。如果在 4 * 复制超时时间内没有收到来自服务器的心跳信号，则认为连接已断开。副本的心跳是对主服务器的心跳的响应，只有在收到主服务器的心跳后才会发送。

正如你所看到的，最后一次心跳交换后，领导者重新启动连接计时器的时间比副本晚。在最坏的情况下，副本的最后一个心跳将在超时时间到期时恰好到达领导者。领导者不知道副本何时发送了它的心跳，它的超时时间可能已经到期。

如果副本除了能够进行快速选举外，还能够保持快速选举，那么旧领导者将辞职得太晚。

因此，为了确保领导者严格在大多数节点开始新选举之前辞职，领导者的超时时间需要是副本的一半。这就是我们要做的。

## 分裂大脑检测

Tarantool 允许你配置一个法定人数。这在很多情况下都很方便；例如，你可以紧急解锁大多数节点已经失败的集群。但这也是危险的：如果法定人数小于 N / 2 + 1，可能会出现两个未连接的领导者。无论是在同一个任期还是在不同的任期中。两个领导者都可以独立确认同步事务并写入异步事务。如果在两个领导者在集群中工作了一段时间后恢复连接，其中一个的更改将覆盖另一个的更改。为了防止这种情况发生，你需要检测到来自竞争领导者的事务，并在不应用它们的情况下终止与发送它们的节点的连接。

## PROMOTE 条目

新领导者出现的标志是 PROMOTE 条目。它包含选举领导者的任期、领导者的 ID、前任领导者的 ID 和前任领导者收到的最后一个 LSN。这些信息足以构建从第一个任期到最后一个任期的线性领导历史。当集群正常运行时，每个传入的 PROMOTE 都与节点已知的信息匹配。任期应该是迄今为止所有 PROMOTE 中最大的，前任领导者的 ID 必须与前一个 PROMOTE 中的 ID 匹配，前任领导者的 LSN 必须与前任领导者的最后一个确认事务的 LSN 匹配。

如果不满足上述条件中的任何一个，那么就发生了分裂大脑。

我们还需要检测旧领导者在新领导者出现在集群中之后继续确认事务的情况。实际上，来自未发送最后一个 PROMOTE 的节点的任何事务都是分裂大脑的指标。

这个最后的例子也解决了我们严格 CheckQuorum 的问题：现在来自旧领导者的任何事务（包括同步和异步）都会导致与其的连接断开，并且不会被应用，从而保持了新领导者及其副本的数据一致性。因此，旧领导者无法影响新领导者及其副本的状态。

## 得到的教训

Raft 算法的经典版本在部分连接丢失的情况下无法提供完整的集群可操作性。为了解决这个问题，使用了以下两个改进：PreVote 和 CheckQuorum。

我们对经典实现的变体允许更快地进行选举并检测到平局，尽管同时需要额外的修改来确保一致性：严格的 CheckQuorum 和分裂大脑检测。

你可以在[官方网站上下载 Tarantool](http://www.tarantool.io/en/download/os-installation/docker-hub/?utm_source=dev&utm_medium=referral&utm_campaign=2022)，并在[我们的 Telegram 聊天中寻求帮助](http://t.me/tarantool?utm_source=dev&utm_medium=referral&utm_campaign=2022)。