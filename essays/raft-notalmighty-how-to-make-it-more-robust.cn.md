# Raft（不是）万能：如何使其更加健壮

[原文链接](https://dev.to/tarantool/raft-notalmighty-how-to-make-it-more-robust-3a11)

[#raf](https://dev.to/t/raf)[#quorum](https://dev.to/t/quorum)[#algorithms](https://dev.to/t/algorithms)[#programming](https://dev.to/t/programming)

大家都喜欢 Raft。人们普遍认为，在分布式系统中使用这个算法意味着这个系统会很好。具体来说：

1. 只要集群中的大多数节点是活动的并且彼此连接，集群就可以进行写操作（在选举领导者时会有暂停）。
2. 如果领导者正常工作并与大多数节点连接，集群将始终可以进行写操作。
3. 如果领导者宕机，将“快速”选择新的领导者，不管“快速”是什么意思。

事实上，仅仅遵循 Raft 规范（https://raft.github.io/raft.pdf 或 Diego Ongaro 的博士论文版本）是不足以实现上述所有内容的。即使 etcd 也曾因此遭受过一次损失，导致 [2020 年 Cloudflare 的故障](https://blog.cloudflare.com/a-byzantine-failure-in-the-real-world/)。

我叫 Sergey Petrenko，我在 Tarantool 上进行复制工作已经有 4 年了。今天我想告诉大家 Raft 算法的弱点以及克服它们的方法。本文是我和 Boris Stepanenko 在 Hydra 2022 上的演讲的自由转述。如果你对 Raft 不熟悉，我建议你先阅读[我的文章](https://dzone.com/articles/raft-in-tarantool-how-it-works-and-how-to-use-it)。

[![图片描述](raft-notalmighty-how-to-make-it-more-robust.en.assets/mt0wckqsxaqv041ulfw3-20240131104950569.png)](https://res.cloudinary.com/practicaldev/image/fetch/s--sRlhwn_T--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/mt0wckqsxaqv041ulfw3.png)

让我从远处开始。假设你有一个使用 Raft 的系统，并且想要在生产环境中使用它。我们都听说过，不止一次地听说过，Raft 保证每个任期内只有一个领导者，并且在集群中失去不到一半的节点的情况下不会丧失性能。也就是说，如果领导者是活动的，它将能够处理条目，如果没有领导者，将选择一个新的领导者。看起来，除了这些保证，我们对系统的长时间运行不需要其他任何东西。事实真的是这样吗？我们即将找到答案。

首先，让我们更仔细地看一下集群只要大多数服务器是活动的并且彼此连接，就能保持运行的说法。对这个说法的误解最终导致了 Cloudflare 的故障。

## 预投票

让我们从一个例子开始。我们将看看在部分连接丢失的情况下 Raft 集群的行为。

![图片描述](raft-notalmighty-how-to-make-it-more-robust.en.assets/ajhkj5j9k9cwbdt6jxtu-20240131104950473.gif)

假设我们的集群由三个节点 A、B 和 C 组成。A 是领导者。B 和 C 是它的副本；这是第 2022 个任期。连接 A 和 C 的丢失会导致什么结果？由于领导者在选举超时期间没有发送心跳，服务器 C 认为领导者丢失，并在第 2023 个任期中开始选举。

服务器 B 是唯一一个服务器 C 可以向其发送 RequestVote 请求的服务器。

一旦服务器 B 收到一个具有更大任期的请求，它也会增加自己的任期。然而，它不一定会投票给 C，因为如果领导者在 A 和 C 之间的连接丢失后写入了一些内容，B 可能拥有更新的数据。

在接收到下一条来自领导者（仍然是服务器 A）的消息时，服务器 B 将报告任期已增加，迫使服务器 A 辞职。集群没有领导者，所以选举开始。在选择领导者之前，集群是不可写的。

如果自连接丢失以来没有新的条目，那么一旦服务器 B 收到服务器 C 的 RequestVote，它将为服务器 C 投票。

[![图片描述](raft-notalmighty-how-to-make-it-more-robust.en.assets/kbg4lpz8u1qzrftjygy9-20240131104950437.png)](https://res.cloudinary.com/practicaldev/image/fetch/s--ech3-gSA--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/kbg4lpz8u1qzrftjygy9.png)

如果发生这种情况，我们就陷入了一个无限循环中：

1. 服务器 C 看不到领导者。
2. 当选举超时到期时，服务器 C 开始新的选举。
3. 通过服务器 B，任期的增加传达给了服务器 A。
4. 服务器 B 为服务器 C 投票，所以
5. 服务器 A 辞职。
6. A 和 C 交换位置，然后从步骤 1 开始重复，但在新的任期中。

连接到这样一个具有闪烁领导者的集群的客户端很可能根本无法写入任何内容。一旦选出了临时领导者，并且客户端尝试执行写操作，领导者就会辞职，甚至不知道应该将写请求转发到哪里，因为它无法直接看到新的领导者。所有这些情况将一直发生，直到至少有一个条目可以被创建，或者直到 A 和 C 之间的连接恢复。这正是 Cloudflare 在 etcd 上遇到的情况。外部系统非常合理地认为，如果它无法向 etcd 集群写入任何内容，那么它意味着其中大多数节点已经失败，需要采取紧急措施。etcd 不可写的短短 6 分钟导致了持续超过 6 小时的事故。

你可能会觉得 Raft 的一些保证在这里被违反了。实际上，并没有。

在任何时刻，领导者都与大多数节点（包括自己）连接，并且领导者本身不会失败。然而，我们的期望被打破了。集群无法正常运行。

但问题是，Raft 从未承诺在这种情况下保证可操作性。它的承诺是“如果大多数节点是功能正常且彼此连接的，将选择一个领导者”。根本没有提到领导者是永久的。并且选择领导者的保证实际上并没有被违反。在上面的例子中，它大约每个选举超时期间确定一次。实际上，Raft 的保证在实践中是不足够的。

但这只是问题的一半。

让我们回到第 2022 个任期，并假设在节点 A、B 和 C 的集群中，节点 C 与其他节点失去了所有通信。服务器 A 是领导者，它仍然与服务器 B 连接，并且可以处理写请求。到目前为止，一切都好。

![图片描述](raft-notalmighty-how-to-make-it-more-robust.en.assets/zu6dftzc89uqcri8nd0m-20240131104950525.gif)

与上面的例子一样，服务器 C 将在每个选举超时期间开始新的选举。当然，服务器 C 无法赢得任何选举。它只是无法获得多数选票。然而，它的任期将无限增长，并且在恢复连接的那一刻，服务器 A 再次辞职，因为它看到了更大的任期。集群再次进入只能读取的状态，至少会有一轮选举。

## Raft 的解决方案

这种“干扰性”服务器的问题实际上是 Raft 的作者 Diego Ongaro 在他的博士论文中提到的。然而，他提到的是与配置更改相关的问题。

他提出的解决方案是称为 Pre-Vote 的选举的新阶段。其思想是每个服务器在选举之前向所有人发送一个模拟投票请求，称为 PreVote。这个请求包含与普通的 RequestVote 相同的字段，投票者根据与 RequestVote 相同的规则对其进行响应。唯一的区别是，投票者在收到此请求时不会增加任期，并且如果它仍然在当前任期中看到领导者，它会否定地回答或者干脆忽略该请求。

只有在收到大多数选民准备好为候选人投票的确认后，候选人才会提升任期并开始真正的选举。

让我们看看 PreVote 是否真的可以拯救 Cloudflare 那次事故。考虑相同的情况，C 与领导者失去了连接，但与其他副本没有失去连接。尽管 C 可以向 B 发送 PreVote 请求，但 B 将否定地回应，因为它仍然看到领导者。C 将无法获得多数选票 —— 有 2 个对其 PreVote 请求的回应。

![图片描述](raft-notalmighty-how-to-make-it-more-robust.en.assets/vp6lymwnb8lvt8iwep5j-20240131104950473.gif)

在完全失去连接并随后恢复连接的情况下，PreVote 也会有所帮助。确实，服务器 C 将无法获得任何 PreVote 请求的响应，因此不会开始选举。

![图片描述](raft-notalmighty-how-to-make-it-more-robust.en.assets/2p8t0b8xi7lzwzck5ohu-20240131104950604.gif)

这种解决方案对我们来说唯一的缺点是违反了向后兼容性。Raft 在 Tarantool 中已经运行了一段时间，协议中没有 PreVote 请求。当然可以添加，但旧的服务器不知道如何处理新的请求。我们需要在发送方引入新的逻辑：如果服务器是旧的，我们不发送 PreVote 请求，并默认假设它肯定会回应。我们不喜欢这种冗余，并且希望摆脱为支持旧版本而存在的额外代码。对我们来说，更好的解决方案是扩展现有请求中的一个。旧的服务器只需忽略现有请求中的新字段，因此不需要额外的逻辑。所以这就是我们选择的方式。

## 我们的解决方案

“在 Tarantool 中，服务器知道在不必要的情况下不会开始选举”，我们这样想，并且我们用我们自己的方式进行了 Pre-Vote。我们让所有副本告诉其他副本它们是否看到当前的领导者。收集到关于谁看到领导者和谁没有看到领导者的信息后，可以决定是否开始选举。如果有任何人看到领导者，或者没有与大多数节点连接，就不会启动选举。

我们解决方案的优势在于它的向后兼容性。我们不需要引入新的请求并以特殊方式将其发送到旧的服务器，如果集群中有不同版本的 Tarantool 服务器。

缺点是我们不比较领导者的日志和选民的日志，这意味着我们即使选民的日志包含更新的数据，也会开始选举。这不一定是件坏事：只要有人看到领导者，就不会进行选举。当每个人都不再看到它时，选举将无论如何开始。它是否在一个或多个轮次内结束并不重要，这要归功于我们的另一个修改，Split-Vote 检测。现在，让我们来谈谈它。

## Split-Vote 检测

这次我没有 Cloudflare 或其他著名公司的可怕案例，但希望它仍然很有趣。

你可能知道，并不是每一轮选举都会产生一个领导者。例如，如果集群中的几个节点同时注意到领导者丢失，它们将在彼此收到 RequestVote 请求之前独立地开始选举。剩下的副本的选票可能会分散在几个候选人之间，以至于没有一个候选人能赢得多数选票。我们将这种情况称为 Split-Vote。

Raft 通过随机化选举超时时间来处理这个问题。在每个服务器和每一轮中，都会选择一个与配置的超时时间略有不同的新随机值。这增加了只有一个候选人有时间开始下一轮选举的机会，而其他候选人在自己的选举超时到期之前会收到来自它的 RequestVote 请求。如果 Raft 没有实现这个功能，选举可能永远不会结束：所有服务器都会同步重新启动，为自己投票。但仍然有优化的空间：每一轮额外的选举都是只读集群停机的选举超时时间。

## 我们的解决方案

实际上，以平局结束的轮次是浪费时间的。如果已经选出了一个领导者，它可能在轮次开始时就会产生。根据 Raft 的规定，选举超时时间要比这个长得多。

此外，与经典的 Raft 实现不同，在 Tarantool 中，服务器不仅将投票信息发送给它投票的候选人，还会发送给所有集群成员。这意味着每个服务器都可以跟踪每个候选人收到的选票数。当看到没有候选人能在当前轮次中获胜时，服务器会加快开始新轮次的速度。从检测到平局到开始新轮次平均需要 0.05 * 选举超时时间。这是因为我们在选举超时时间 / 10 的范围内选择一个随机延迟来重新启动选举。我们之所以这样做，完全出于与 Raft 相同的目的：避免新的平局。因此，在最好的情况下，我们在每个具有平局的轮次上节省了大约 0.9 * 选举超时时间。这种改进是非常明显的：在原始的 Raft 中，在两轮选举中选出领导者意味着花费了大约选举超时时间 + 选举超时时间的一部分时间。然而，使用我们的实现，两轮这样的选举只需要不到一个选举超时时间的一部分时间。这比原始的 Raft 意识到发生平局所需的时间更快。

在最坏的情况下，当连续发生两次平局时，我们处理得更快。对我们来说，每一轮平局几乎没有成本。此外，我们不会以任何方式增加第二次平局的概率：在这种情况下，重新启动选举的随机延迟在与通常情况下相同的范围内生成。

## CheckQuorum

Raft 确保在一个任期内不会有两个领导者。然而，并没有说在同一时间可能存在两个领导者的可能性：在旧任期和新任期中。我们肯定希望避免这种情况的发生。原因是连接到旧领导者的客户端可能不知道有新领导者存在。直到旧领导者实际辞职之前，他们根本没有理由寻找新领导者。旧领导者仍然是可写的，同步事务将在未能从大多数副本获得确认时回滚。

对于我们来说，同时存在两个领导者的情况可能是关键的，因为 Tarantool 不仅支持同步复制，还支持异步复制。每个领导者都是可写的，如果你在旧领导者上写入异步事务，客户端可能会忽略新领导者的存在。这将导致一些客户端联系新领导者，而另一些客户端联系旧领导者。我们将遇到脑裂问题。为了避免这种情况，旧领导者必须在有可能被取代时辞职并进入只读状态。

只有当旧领导者与集群中大多数服务器失去连接时，才可能出现两个领导者同时存在的情况。实际上，要赢得选举，你必须获得多数选票，旧领导者之所以不知道选举的情况，是因为它与大多数节点没有连接。如果它与至少一个投票给新领导者的服务器连接，它会立即辞职。而且不可能出现旧领导者与大多数节点中没有人投票，同时新领导者与投票多数节点连接的情况。

因此，我们希望确保领导者在失去与集群大多数节点的连接后立即辞职。如果当前领导者的连接丢失，很可能大多数已经选择了另一个领导者。

还有另一个原因需要 CheckQuorum：如果只有 PreVote，集群可能会被锁定：当前领导者无法写入任何内容，副本也无法开始选举。让我们看一个例子：假设我们有一个由五个服务器组成的集群，其中 D 是领导者。接下来发生了一系列非同寻常的事件：首先，服务器 E 崩溃，然后由于某种原因 A 和 D 之间的连接中断，最后，由于另一种原因，C 和 D 之间的连接中断。

结果，尽管服务器 D 仍然是领导者，但它无法提交同步事务，因为它无法获得三个确认。服务器 B 不会开始选举，因为它仍然看到领导者 D。服务器 A 和 C 不会开始选举，因为服务器 B 告诉它们领导者是活动的。

![图片描述](raft-notalmighty-how-to-make-it-more-robust.en.assets/oizii764s48dq1tm3c49-20240131104950552.gif)

CheckQuorum 通过使失去与大多数集群连接的领导者辞职并允许其中一个副本接替它的位置来帮助解决这个问题。

![图片描述](raft-notalmighty-how-to-make-it-more-robust.en.assets/hch89oq8nf174a838uj4-20240131104950558.gif)

现在需要决定领导者应该在什么时候辞职。对于被阻塞的集群示例，实际上并不重要。这里的主要问题是，领导者最终会辞职，使其副本可以开始选举。

如果只涉及同步复制，一切都会很好。辞职的速度也不重要。旧领导者无法确认连接中断后的任何同步事务。

如果涉及异步事务，你必须采取一些措施来确保一致性。

**最低要求**是旧领导者必须在副本开始选举之前**严格**辞职。这是为了确保集群不会同时拥有两个可写节点。我们将这种模式称为严格的 CheckQuorum。

但这还不够。我们无法保证在连接失败后不会写入任何异步事务。无论如何，要检测到连接失败，需要一些时间，无论多短。这意味着旧领导者可能会写入新领导者没有的事务。当最终恢复连接时，事务将传达给其他节点，并且新领导者写入的所有内容的一致性可能会受到损害。因此，我们的最终目标。

**最终目标：**在恢复连接后，新领导者及其所有副本不得应用由前任领导者记录的事务。我们将在下一章中更详细地介绍这个问题，但现在让我们讨论如何实现所需的最低要求。

领导者和副本都通过心跳监控连接的状态。如果在 4 * 复制超时时间内没有收到来自服务器的心跳，就认为连接已断开。副本的心跳是对主服务器的心跳的响应，只有在收到主服务器的心跳后才会发送。

正如你所看到的，最后一次心跳交换后，领导者重新启动连接计时器的时间比副本晚。在最坏的情况下，副本的最后一个心跳将在超时时间到期时恰好到达领导者。领导者不知道副本何时发送了它的心跳，它的超时时间可能已经到期。

如果副本除了能够进行快速选举外，还能够进行快速选举，那么旧领导者将辞职得太晚。

因此，为了确保领导者严格在大多数节点开始新选举之前辞职，领导者的超时时间需要是副本的一半。这就是我们要做的。

## Split-Brain 检测

Tarantool 允许你配置一个法定人数。这在很多情况下都很方便；例如，你可以紧急解锁大多数节点已经失败的集群。但这也是危险的：如果法定人数小于 N / 2 + 1，可能会有两个无法连接的领导者。无论是在同一个任期还是在不同的任期中。这两个领导者都可以独立地确认同步事务并写入异步事务。如果在两个领导者在集群中工作一段时间后恢复连接，其中一个的更改将覆盖另一个的更改。为了防止这种情况发生，你需要检测到来自竞争领导者的事务，并在不应用它们的情况下终止与发送它们的节点的连接。

## PROMOTE 条目

新领导者出现的标志是 PROMOTE 条目。它包含选举领导者的任期、领导者的 ID、前任领导者的 ID 和前任领导者收到的最后一个 LSN。这些信息足以构建从第一个任期到最后一个任期的线性领导历史。当集群正常运行时，每个传入的 PROMOTE 都与节点已知的信息进行匹配。任期应该是迄今为止所有 PROMOTE 中最大的，前任领导者的 ID 必须与前一个 PROMOTE 中的 ID 匹配，前任领导者的 LSN 必须与前任领导者的最后一个已确认事务的 LSN 匹配。

如果上述条件中的任何一个不满足，那么就发生了脑裂。

我们还需要检测旧领导者在新领导者出现在集群中之后继续确认事务的情况。实际上，来自未发送最后一个 PROMOTE 的节点的任何事务都是脑裂的指标。

这个最后的例子也解决了我们在严格 CheckQuorum 中的问题：现在来自旧领导者的任何事务（包括同步和异步事务）都会导致与其的连接断开，并且不会被应用，从而保持了新领导者及其副本的数据一致性。因此，旧领导者无法影响新领导者及其副本的状态。

## 吸取的教训

Raft 算法的经典版本在部分连接丢失的情况下无法提供完整的集群可操作性。为了解决这个问题，使用了以下两个改进：PreVote 和 CheckQuorum。

我们对经典实现的变体允许更快地进行选举并检测到平局，尽管同时需要额外的修改来确保一致性：严格的 CheckQuorum 和 Split-Brain 检测。

你可以在[官方网站上下载 Tarantool](http://www.tarantool.io/en/download/os-installation/docker-hub/?utm_source=dev&utm_medium=referral&utm_campaign=2022)，并在[我们的 Telegram 聊天中寻求帮助](http://t.me/tarantool?utm_source=dev&utm_medium=referral&utm_campaign=2022)。